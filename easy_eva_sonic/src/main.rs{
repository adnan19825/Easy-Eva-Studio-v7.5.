use anyhow::{Error as E, Result};
use candle_core::{Device, Tensor};
use candle_transformers::models::quantized_llama::ModelWeights as QLlama;
use tokenizers::Tokenizer;
use std::process::Command;
use dotenvy::dotenv;
use std::time::Duration;
use std::collections::HashSet;

mod comms;

fn get_node_info() -> String {
    let hostname = Command::new("hostname").output().map(|o| String::from_utf8_lossy(&o.stdout).trim().to_string()).unwrap_or_else(|_| "unknown".to_string());
    let ip = Command::new("sh").arg("-c").arg("ifconfig | grep 'inet ' | grep -v '127.0.0.1' | awk '{print $2}' | head -n 1").output().map(|o| String::from_utf8_lossy(&o.stdout).trim().to_string()).unwrap_or_else(|_| "no-ip".to_string());
    format!("Node: {} | IP: {}", hostname, ip)
}

fn get_real_processes() -> Vec<String> {
    let output = Command::new("sh").arg("-c").arg("ps -A --format comm").output().map(|o| String::from_utf8_lossy(&o.stdout).to_string()).unwrap_or_else(|_| "error".to_string());
    output.lines().skip(1).map(|s| s.trim().to_string()).filter(|s| !s.is_empty()).collect()
}

struct LocalAIModule {
    model: QLlama,
    tokenizer: Tokenizer,
    device: Device,
}

impl LocalAIModule {
    pub fn load(model_path: &str) -> Result<Self> {
        let device = Device::Cpu;
        let mut file = std::fs::File::open(model_path)?;
        let content = candle_core::quantized::gguf_file::Content::read(&mut file)?;
        let model = QLlama::from_gguf(content, &mut file, &device)?;
        let tokenizer = Tokenizer::from_file("../assets/tokenizer.json").map_err(E::msg)?;
        Ok(Self { model, tokenizer, device })
    }

    pub fn analyze(&mut self, text: &str) -> Result<String> {
        let prompt = format!("<|system|>\nSecurity analyst. ONE word.\n<|user|>\nAnalyze: {}\n<|assistant|>\nVerdict:", text);
        let tokens = self.tokenizer.encode(prompt, true).map_err(E::msg)?;
        let input = Tensor::new(tokens.get_ids(), &self.device)?.unsqueeze(0)?;
        let mut output_tokens = Vec::new();
        let mut current_input = input.clone();
        for _ in 0..10 {
            let logits = self.model.forward(&current_input, output_tokens.len())?;
            let logits = logits.squeeze(0)?;
            let next_token = if logits.rank() >= 2 {
                let (seq_len, _) = logits.dims2()?;
                logits.get(seq_len - 1)?.argmax(0)?.to_scalar::<u32>()?
            } else { logits.argmax(0)?.to_scalar::<u32>()? };
            if next_token == 2 { break; } 
            output_tokens.push(next_token);
            current_input = Tensor::new(&[next_token], &self.device)?.unsqueeze(0)?;
        }
        Ok(self.tokenizer.decode(&output_tokens, true).map_err(E::msg)?.trim().to_uppercase())
    }
}

#[tokio::main]
async fn main() -> Result<()> {
    dotenv().ok();
    let info = get_node_info();
    println!("üîß EASY-EVA SONIC (v10.6 Learning Edition)");
    println!("üìç {}", info);
    
    let mut ai = LocalAIModule::load("../assets/tinyllama.gguf")?;
    let mut baseline = HashSet::new();

    // LERNPHASE (Baseline erstellen)
    println!("üéì LERNPHASE: Erfasse Normalzustand (30 Sek)...");
    for i in 1..=5 {
        let all_procs = get_real_processes();
        
        // DEBUG: Zeige uns, was gerade l√§uft, wenn du unsicher bist
        // println!("Aktuelle Prozesse: {:?}", all_procs);

        let anomalies: Vec<String> = all_procs.iter()
            .map(|p| p.trim().to_string()) // Alles trimmen!
            .filter(|p| {
                // Pr√ºfe, ob der Prozess in der Baseline ist
                // Wir nutzen .contains, falls Pfade involviert sind
                !baseline.iter().any(|b| b.trim() == p)
            })
            .collect();

        for p in procs { baseline.insert(p); }
        println!("   [{}/5] Samples gesammelt...", i);
        tokio::time::sleep(Duration::from_secs(6)).await;
    }
    println!("‚úÖ Baseline erstellt. {} Prozesse als sicher markiert.", baseline.len());
    println!("---------------------------------------------------");

    let mut last_verdict = String::new();

        
        // Finde Prozesse, die NICHT in der Baseline sind
        let anomalies: Vec<String> = all_procs.iter()
            .filter(|p| !baseline.contains(*p))
            .cloned()
            .collect();

        if anomalies.is_empty() {
            println!("[{}] üõ°Ô∏è Status: SAFE (Keine Anomalien).", now);
        } else {
            let anomaly_list = anomalies.join(", ");
            println!("[{}] üîç Anomalie entdeckt: {}", now, anomaly_list);
            
            let raw_verdict = ai.analyze(&anomaly_list)?;
            let is_safe = raw_verdict.contains("SAFE") && !raw_verdict.contains("RISK");
            let current_verdict = if is_safe { "SAFE".to_string() } else { "RISK".to_string() };

            if current_verdict != last_verdict && current_verdict == "RISK" {
                println!("[{}] üö® ALARM! Sende Ticket...", now);
                if let Ok(token) = std::env::var("GITHUB_TOKEN") {
                    let reporter = comms::GitHubReporter::new(token)?;
                    let details = format!("System: {}\nAnomalien: {}", info, anomaly_list);
                    let _ = reporter.create_security_alert(&current_verdict, 1, &details).await;
                }
                last_verdict = current_verdict;
            }
        }
        
        tokio::time::sleep(Duration::from_secs(60)).await;
    }
}

